================================================================================
DATABASE SCHEMA INTEGRATION AUDIT - CRITICAL ISSUES SUMMARY
Migration: 20251123000000_enhance_memory_system.sql
Date: 2025-11-23
================================================================================

CRITICAL FINDING: This migration will PERMANENTLY DELETE all memory_notes data

================================================================================
QUICK REFERENCE: Issues by Severity
================================================================================

CRITICAL (1 issue - BLOCKS MIGRATION)
  [1] DROP TABLE memory_notes CASCADE
      - Deletes all existing memory records
      - No backup, no recovery path
      - Data loss risk: 100%

HIGH (3 issues - IMPACTS FUNCTIONALITY)
  [2] backtest_runs column additions (regime_id, regime_context, statistical_validity)
      - Safe IF NOT EXISTS clauses
      - No data loss risk

  [3] Foreign key references (workspaces, backtest_runs)
      - All references valid
      - No structural integrity risk

  [7] Index namespace collisions
      - No collisions detected
      - All index names unique

MEDIUM (4 issues - REQUIRES FIXES)
  [4] Migration order & pgvector dependency
      - Safe if Supabase applies migrations in timestamp order
      - Currently satisfied

  [5] Function search_path regression
      - Removes search_path = public from update_updated_at_column()
      - May cause subtle "function not found" errors
      - FIX: Add "SET search_path = public" back

  [6] Trigger creation idempotency
      - CREATE TRIGGER will fail on rerun
      - FIX: Add IF NOT EXISTS (Postgres 14+)

  [8] Hybrid search function API change
      - New hybrid_search_memories() replaces search_memory_notes()
      - Old function references dropped memory_notes table
      - FIX: Update application code to use new function

================================================================================
ISSUE DETAILS
================================================================================

[CRITICAL #1] DROP TABLE memory_notes CASCADE
─────────────────────────────────────────────
Location: Line 4-5
Code:
  DROP TABLE IF EXISTS memory_notes CASCADE;
  CREATE TABLE IF NOT EXISTS memories (...)

Impact:
  • All memory records are permanently deleted
  • Affected data: Potentially 2,000-10,000 memory records
  • Lost fields: embeddings, vectors, metadata, run links
  • Cascade: If other tables FK to memory_notes, their references lost

Current Table State:
  Existing memory_notes table contains:
    • content (TEXT)
    • source (manual/auto)
    • tags (TEXT[])
    • embedding (vector(1536)) - from migration 20251119184427
    • memory_type (text) - from migration 20251119184913
    • importance (text) - from migration 20251119184913
    • updated_at (TIMESTAMPTZ) - from migration 20251119194458
    • archived (BOOLEAN) - from migration 20251119194458
    • run_id (UUID FK) - from migration 20251119183154
    • metadata (JSONB) - from migration 20251119183154

Why This Matters:
  Memory notes contain:
    • Trading rules discovered through testing
    • Risk management principles
    • Overfitting warnings and failure modes
    • Regime-specific insights
    • Backtest run annotations

Solutions:
  A. Data Migration (Preserve existing knowledge)
     - INSERT FROM memory_notes → memories
     - Map columns (run_id, metadata, etc.)
     - Verify counts match

  B. Backup & Reset (Start fresh)
     - CREATE TABLE memory_notes_backup AS SELECT * FROM memory_notes
     - Drop memory_notes
     - Accept knowledge loss

  C. Parallel Tables (Gradual migration)
     - Keep memory_notes
     - Create memories table alongside
     - Migrate application code incrementally

Recommendation: Option A (Data Migration) preserves institutional knowledge


[HIGH #2] backtest_runs Column Additions
─────────────────────────────────────────
Location: Line 86-88
Code:
  ALTER TABLE backtest_runs ADD COLUMN IF NOT EXISTS regime_id INTEGER;
  ALTER TABLE backtest_runs ADD COLUMN IF NOT EXISTS regime_context JSONB DEFAULT '{}';
  ALTER TABLE backtest_runs ADD COLUMN IF NOT EXISTS statistical_validity JSONB DEFAULT '{}';

Status: SAFE
  • Uses IF NOT EXISTS - idempotent
  • Defaults sensible (NULL, empty object)
  • No existing column conflicts
  • No data loss

Action: None required - already safe


[HIGH #3] Foreign Key References
──────────────────────────────────
Tables Created: memories, trading_rules, regime_profile_performance, market_events, overfitting_warnings

Foreign Key Validation:
  memories.workspace_id → workspaces(id)
    Status: ✓ VALID (created 20251119174252)

  trading_rules.workspace_id → workspaces(id)
    Status: ✓ VALID

  regime_profile_performance.workspace_id → workspaces(id)
    Status: ✓ VALID

  market_events.workspace_id → workspaces(id)
    Status: ✓ VALID

  overfitting_warnings.workspace_id → workspaces(id)
    Status: ✓ VALID

  overfitting_warnings.run_id → backtest_runs(id)
    Status: ✓ VALID (created 20251119174252)

  memory_evidence.memory_id → memories(id)
    Status: ✓ VALID (created in same migration)

Action: None required - all references valid


[HIGH #7] Index Namespace Collisions
─────────────────────────────────────
New Indexes Created: 23 total
  • idx_memories_* (8 indexes) - new table, no conflicts
  • idx_rpp_* (4 indexes) - new table, no conflicts
  • idx_evidence_* (2 indexes) - new table, no conflicts
  • idx_overfitting_* (3 indexes) - new table, no conflicts
  • idx_events_* (2 indexes) - new table, no conflicts

Existing Indexes (not affected):
  • idx_memory_notes_* (from memory_notes table)
  • idx_backtest_runs_* (existing)
  • idx_chat_sessions_* (existing)
  • etc.

Status: NO COLLISIONS DETECTED
  New migration uses distinct index prefixes
  No namespace overlap with existing indexes

Action: None required - safe


[MEDIUM #4] Migration Order & Dependencies
────────────────────────────────────────────
Dependency: pgvector extension

Timeline:
  20251119184427: CREATE EXTENSION IF NOT EXISTS vector;
  20251123000000: Uses vector(1536) type (assumes pgvector exists)

Status: SAFE
  Supabase applies migrations in timestamp order
  pgvector created BEFORE new migration runs
  All vector columns will work correctly

Action: None required - dependencies satisfied


[MEDIUM #5] Function search_path Regression
──────────────────────────────────────────────
Location: Line 270-276
Current Code:
  CREATE OR REPLACE FUNCTION update_updated_at_column()
  RETURNS TRIGGER AS $$
  BEGIN
    NEW.updated_at = NOW();
    RETURN NEW;
  END;
  $$ LANGUAGE plpgsql;

Previous Version (20251119174321):
  $$ LANGUAGE plpgsql SET search_path = public;

Issue:
  • search_path = public was added in 20251119174321 to prevent errors
  • New migration removes it (reverts to earlier version)
  • May cause "function not found" errors in trigger execution

Risk: MEDIUM
  • Subtle issue - function works in simple cases
  • May fail in complex scenarios with schema-qualified calls
  • Hard to debug once in production

Fix (Recommended):
  $$ LANGUAGE plpgsql SET search_path = public;

Action: Required - add search_path back


[MEDIUM #6] Trigger Creation Idempotency
──────────────────────────────────────────
Location: Line 278-281
Code:
  CREATE TRIGGER update_memories_updated_at
    BEFORE UPDATE ON memories
    FOR EACH ROW
    EXECUTE FUNCTION update_updated_at_column();

Issue:
  • CREATE TRIGGER fails if trigger already exists
  • Running migration twice will error
  • Supabase usually prevents reruns, but not guaranteed

Current Behavior:
  • First run: SUCCESS
  • Second run (if attempted): ERROR - trigger already exists

Modern PostgreSQL (14+) Solution:
  CREATE TRIGGER IF NOT EXISTS update_memories_updated_at
    BEFORE UPDATE ON memories
    FOR EACH ROW
    EXECUTE FUNCTION update_updated_at_column();

Action: Recommended - add IF NOT EXISTS


[MEDIUM #8] Hybrid Search Function API Change
──────────────────────────────────────────────
New Function: hybrid_search_memories()
  Location: Line 284-355
  Purpose: BM25 + Vector hybrid search on memories table
  Parameters:
    - query_text (TEXT)
    - query_embedding (vector(1536))
    - match_workspace_id (UUID)
    - limit_count (INTEGER, default 20)
    - bm25_weight (REAL, default 0.3)
    - vector_weight (REAL, default 0.7)
    - min_importance (REAL, default 0.0)

Old Function: search_memory_notes()
  Location: Defined in 20251119184427, updated through 20251119194601
  Purpose: Vector search on memory_notes table
  Status AFTER migration: BROKEN (references dropped table)

Impact:
  • Application code calling search_memory_notes() will fail
  • Function still exists but queries dropped table
  • Queries will error: "relation 'public.memory_notes' does not exist"

Application Code Change Required:
  OLD:
    SELECT * FROM search_memory_notes(
      query_embedding => $1,
      match_workspace_id => $2,
      match_threshold => 0.7,
      match_count => 5
    );

  NEW:
    SELECT * FROM hybrid_search_memories(
      query_text => $3,
      query_embedding => $1,
      match_workspace_id => $2,
      limit_count => 5,
      bm25_weight => 0.3,
      vector_weight => 0.7,
      min_importance => 0.0
    );

Files to Update:
  • Any API endpoint calling search_memory_notes()
  • Any ORM query building this function call
  • Any stored procedure wrapping this function
  • Any test queries using search_memory_notes()

Action: Required - update application code


================================================================================
EXECUTION CHECKLIST
================================================================================

PRE-MIGRATION (Do First)
  [ ] Backup memory_notes table
  [ ] Count rows in memory_notes (SELECT COUNT(*) ...)
  [ ] Review memory_notes content (sample queries)
  [ ] Identify all code calling search_memory_notes()
  [ ] Document current memory usage
  [ ] Get stakeholder approval for data migration approach
  [ ] Test in development environment first

DATA MIGRATION (Choose One)
  [ ] Option A: INSERT INTO memories SELECT ... FROM memory_notes;
  [ ] Option B: CREATE TABLE memory_notes_backup AS SELECT * FROM memory_notes;
  [ ] Option C: Keep both tables, migrate incrementally

FIX CODE ISSUES (Before Applying)
  [ ] Add SET search_path = public to function (line 276)
  [ ] Add IF NOT EXISTS to trigger (line 278)
  [ ] No changes needed for FKs or indexes
  [ ] pgvector dependency already satisfied

UPDATE APPLICATION CODE
  [ ] Replace search_memory_notes() calls with hybrid_search_memories()
  [ ] Update function parameters (add query_text, adjust weights)
  [ ] Test all memory search paths
  [ ] Update ORM models to use memories table
  [ ] Update UI/API if it references memory_notes directly

APPLY MIGRATION
  [ ] Apply 20251123000000_enhance_memory_system.sql
  [ ] Verify all tables exist: \dt memories, trading_rules, ...
  [ ] Verify all indexes exist: \di idx_memories_*, idx_rpp_*, ...
  [ ] Verify all functions exist: \df hybrid_search_memories, ...
  [ ] Verify all triggers exist: \dt+ memories

POST-MIGRATION (Verify Success)
  [ ] Test hybrid_search_memories() with sample queries
  [ ] Test memory creation on memories table
  [ ] Test regime_profile_performance inserts
  [ ] Test overfitting_warnings inserts
  [ ] Verify all FKs still work
  [ ] Monitor application for errors
  [ ] Check logs for "relation not found" errors


================================================================================
SUMMARY STATISTICS
================================================================================

Migration File: 20251123000000_enhance_memory_system.sql
Total Lines: 425

New Tables: 6
  • memories (69 lines)
  • memory_extraction_state (8 lines)
  • trading_rules (13 lines)
  • regime_profile_performance (14 lines)
  • memory_queries (10 lines)
  • market_events (18 lines)
  • memory_evidence (10 lines)

Altered Tables: 1
  • backtest_runs (3 columns added)

Dropped Tables: 1
  • memory_notes (CRITICAL DATA LOSS)

New Indexes: 23 total
  • memories: 8
  • regime_profile_performance: 4
  • market_events: 2
  • memory_evidence: 2
  • overfitting_warnings: 3
  • memory_queries: 0

New Functions: 4
  • update_updated_at_column() - recreated
  • hybrid_search_memories() - new
  • find_similar_warnings() - new
  • get_regime_performance() - new

New Triggers: 1
  • update_memories_updated_at

Issues Identified:
  • Critical: 1 (data loss)
  • High: 3 (safe, but noted)
  • Medium: 4 (require fixes/updates)
  • Total: 8

Blocking Issues: 1
  • DROP TABLE memory_notes (must handle before applying)

Recommended Fixes: 3
  • Add search_path to function
  • Add IF NOT EXISTS to trigger
  • Update application code


================================================================================
RECOMMENDATIONS
================================================================================

PRIORITY 1: Handle Data Loss (CRITICAL)
  Before applying migration, choose a data preservation strategy:
    A. Data Migration (recommended): INSERT INTO memories SELECT FROM memory_notes
    B. Backup & Reset: Accept data loss, backup table for reference
    C. Parallel Tables: Keep both, migrate application gradually

  Estimated time: 30-60 minutes of planning + testing

PRIORITY 2: Fix Code Issues (MEDIUM)
  Before applying migration, fix 3 issues:
    1. Add SET search_path = public to function (1 line change)
    2. Add IF NOT EXISTS to trigger (1 word change)
    3. Test both changes in development

  Estimated time: 15 minutes

PRIORITY 3: Update Application (MEDIUM)
  After migration, update application code:
    1. Replace search_memory_notes() with hybrid_search_memories()
    2. Update function parameters
    3. Update ORM models
    4. Test all memory operations

  Estimated time: 1-2 hours (depends on codebase size)

TOTAL ESTIMATED TIME: 2-4 hours for safe, complete migration

================================================================================
NEXT STEPS
================================================================================

1. Read full audit: /Users/zstoc/GitHub/quant-chat-scaffold/.claude/audit/SCHEMA_INTEGRATION_AUDIT_20251123.md

2. Make decision on data preservation:
   - Option A (preserve): Code data migration INSERT statement
   - Option B (reset): Accept data loss, document reason
   - Option C (parallel): Plan incremental migration timeline

3. Prepare fixes:
   - Fix #1: Add search_path to function
   - Fix #2: Add IF NOT EXISTS to trigger

4. Update code:
   - Find all search_memory_notes() calls
   - Replace with hybrid_search_memories()
   - Update function parameters

5. Test:
   - Test in development environment
   - Verify backups
   - Verify old table preserved (if using Option C)

6. Deploy:
   - Apply migration
   - Verify tables/functions/triggers
   - Monitor for errors
   - Verify application works

================================================================================
Questions?
================================================================================

For detailed analysis of each issue, see:
  SCHEMA_INTEGRATION_AUDIT_20251123.md

For specific SQL fixes, see:
  "Recommended Fixes" section of full audit

For migration step-by-step guide, see:
  "Migration Execution Plan" section of full audit

================================================================================
